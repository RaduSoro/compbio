{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-177a63d6e338>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from tools import util_resize\n",
    "from tools import skew_correction\n",
    "from tools import shape_operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# good shape of the rectange for Passport2\n",
    "# oritation rotation were correct for all images. but it could be 90 or 180 wrong. e.g. upside down\n",
    "# according to contour and hough lines to minimise the rectangle\n",
    "# assume the orientation has corrected.\n",
    "# this experiment shows that the gaussian blur with kernel=np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]] can highlight the hough lines,\n",
    "# but it is not good for canny contour\n",
    "# try canny without blur\n",
    "# use shape_operation functions\n",
    "# all well. Change contour mask by bgr gray otsu\n",
    "# first do the common one with similar background, then do the complex background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#== Parameters\n",
    "BLUR = 21\n",
    "CANNY_THRESH_1 = 10\n",
    "CANNY_THRESH_2 = 40  # Change to\n",
    "MASK_DILATE_ITER = 10\n",
    "MASK_ERODE_ITER = 10\n",
    "MASK_COLOR = (0.0, 0.0, 1.0) # In RBG format\n",
    "MORPH_KERNEL_RECT_7 = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "MORPH_KERNEL_RECT_5 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# test_file = open('./images/passport2.jpeg')\n",
    "# for line in test_file:\n",
    "#     print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# common part to get the gray image with fixed size\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "file_path = './images/'\n",
    "filename = 'Passport2.jpeg'\n",
    "# filename = 'scan2.jpeg'\n",
    "filename = 'passp3.jpg'\n",
    "filename = 'out001.jpg'\n",
    "filename = 'passport_01.jpg'\n",
    "# filename = 'Order-all-sorts-of-documents-online.jpeg'\n",
    "# filename = 'image_111.jpg'\n",
    "\n",
    "\n",
    "img_file_name = file_path + filename\n",
    "img_org = cv2.imread(img_file_name)\n",
    "\n",
    "img_input_uniform_color = util_resize.image_to_fixed_size_wo_distortion(img_org, height=800)\n",
    "plt.subplot(171).set_title('img_input_uniform_color'), plt.imshow(img_input_uniform_color)\n",
    "\n",
    "# hsv transform - value = gray image\n",
    "hsv = cv2.cvtColor(img_input_uniform_color, cv2.COLOR_BGR2HSV)\n",
    "hue, saturation, img_input_hsv_gray = cv2.split(hsv)\n",
    "plt.subplot(172).set_title('img_input_hsv_gray'), plt.imshow(img_input_hsv_gray, cmap='gray')\n",
    "\n",
    "img_input_hsv_gray_blur = cv2.GaussianBlur(img_input_hsv_gray, (3, 3), 0)\n",
    "plt.subplot(173).set_title('img_input_hsv_gray_blur'), plt.imshow(img_input_hsv_gray_blur, cmap='gray')\n",
    "\n",
    "ret, img_input_hsv_gray_otsu_thresh =cv2.threshold(img_input_hsv_gray_blur, 0, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "plt.subplot(174).set_title('img_input_hsv_gray_otsu_thresh'), plt.imshow(img_input_hsv_gray_otsu_thresh, cmap='gray')\n",
    "\n",
    "# plt.subplot(166).set_title('img_rotated_max_contour_mask_blur'), plt.imshow(img_rotated_max_contour_mask, cmap='gray')\n",
    "img_input_bgr_gray = cv2.cvtColor(img_input_uniform_color, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(175).set_title('img_input_bgr_gray'), plt.imshow(img_input_bgr_gray, cmap='gray')\n",
    "#\n",
    "img_input_bgr_gray_blur = cv2.GaussianBlur(img_input_bgr_gray, (3, 3), 0)\n",
    "plt.subplot(176).set_title('img_input_bgr_gray_blur'), plt.imshow(img_input_bgr_gray_blur, cmap='gray')\n",
    "\n",
    "ret, img_input_bgr_gray_otsu_thresh =cv2.threshold(img_input_bgr_gray_blur, 0, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "plt.subplot(177).set_title('img_input_bgr_gray_otsu_thresh'), plt.imshow(img_input_bgr_gray_otsu_thresh, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# img_input_bgr_gray_otsu_thresh = img_input_bgr_gray_otsu_thresh - img_input_bgr_gray_blur\n",
    "# plt.imshow(img_input_bgr_gray_otsu_thresh - img_input_bgr_gray_blur, cmap='gray')\n",
    "\n",
    "# img_input_canny = cv2.Canny(img_input_bgr_gray_otsu_thresh, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "# # print(img_input_bgr_gray_otsu_thresh[100][:])\n",
    "# plt.imshow(img_input_canny, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# step 1: get the contour mask of the input image.\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "\n",
    "###### do canny, closing, max contour,  ######\n",
    "# img_input_canny = cv2.Canny(img_input_hsv_gray_otsu_thresh, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "img_input_canny = cv2.Canny(img_input_bgr_gray_otsu_thresh, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "# plt.subplot(161).set_title('img_input_canny'), plt.imshow(img_input_canny, cmap='gray')\n",
    "\n",
    "img_input_canny_closing = cv2.morphologyEx(img_input_canny, cv2.MORPH_CLOSE, MORPH_KERNEL_RECT_7)\n",
    "# img_input_closing = 255 - img_input_closing\n",
    "# plt.subplot(162).set_title('img_input_canny_closing'), plt.imshow(img_input_canny_closing, cmap='gray')\n",
    "\n",
    "img_input_contour_info = []\n",
    "# _, contours, _ = cv2.findContours(img_input_closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# _, contours, _ = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "_, contours, _ = cv2.findContours(img_input_canny_closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in contours:\n",
    "    img_input_contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c),))\n",
    "img_input_contour_sorted = sorted(img_input_contour_info, key=lambda c: c[2], reverse=True)\n",
    "img_input_max_contour = img_input_contour_sorted[0]\n",
    "\n",
    "cnt = cv2.convexHull(img_input_max_contour[0])\n",
    "rect = cv2.minAreaRect(cnt)\n",
    "# width = rect[1][0]\n",
    "# height = rect[1][1]\n",
    "\n",
    "# draw contour and min rectangle\n",
    "box = cv2.boxPoints(rect)\n",
    "box = np.int0(box)\n",
    "print(box)\n",
    "\n",
    "# show minimal area rectangle\n",
    "cv2.drawContours(img_input_canny, [img_input_max_contour[0]], 0, (0,0,255), 3)\n",
    "cv2.drawContours(img_input_canny, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "# get the percentage of contour area against the whole image\n",
    "max_contour_area = (img_input_max_contour[2])\n",
    "max_contour_rect_area =  rect[1][0] * rect[1][1]\n",
    "whole_area = img_input_canny_closing.shape[0] * img_input_canny_closing.shape[1]\n",
    "print('Contour area to whole percentage: ', max_contour_area, whole_area, max_contour_area/whole_area*100)\n",
    "print('Contour area to rect percentage: ', max_contour_area, max_contour_rect_area, max_contour_area/max_contour_rect_area*100)\n",
    "\n",
    "mix_background = max_contour_area < whole_area * 0.9\n",
    "if (mix_background):  # pixel value of background is higher than the object\n",
    "    print('complex background')\n",
    "    plt.subplot(161).set_title('img_input_canny'), plt.imshow(img_input_canny, cmap='gray')\n",
    "    plt.subplot(162).set_title('img_input_canny_closing'), plt.imshow(img_input_canny_closing, cmap='gray')\n",
    "    \n",
    "else:  # contour is almost the whole image, probablely the background has high pixel value\n",
    "    img_input_canny = cv2.Canny(img_input_bgr_gray_otsu_thresh, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "    plt.subplot(161).set_title('img_input_canny'), plt.imshow(img_input_canny_closing, cmap='gray')\n",
    "    \n",
    "    img_input_canny_closing = cv2.morphologyEx(img_input_canny, cv2.MORPH_CLOSE, MORPH_KERNEL_RECT_7)\n",
    "    # img_input_closing = 255 - img_input_closing\n",
    "    plt.subplot(162).set_title('img_input_closing'), plt.imshow(img_input_canny_closing, cmap='gray')\n",
    "\n",
    "    img_input_contour_info = []\n",
    "    # _, contours, _ = cv2.findContours(img_input_closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # _, contours, _ = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours, _ = cv2.findContours(img_input_canny_closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        img_input_contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c),))\n",
    "    img_input_contour_sorted = sorted(img_input_contour_info, key=lambda c: c[2], reverse=True)\n",
    "    img_input_max_contour = img_input_contour_sorted[0]\n",
    "    \n",
    "img_input_max_contour_mask = np.zeros(img_input_canny_closing.shape)\n",
    "cv2.fillConvexPoly(img_input_max_contour_mask, img_input_max_contour[0], (255, 0, 0))\n",
    "plt.subplot(163).set_title('img_input_max_contour_mask'), plt.imshow(img_input_max_contour_mask, cmap='gray')\n",
    "\n",
    "img_input_max_contour_mask_erode = cv2.erode(img_input_max_contour_mask, None, iterations=MASK_ERODE_ITER)\n",
    "plt.subplot(164).set_title('img_input_max_contour_mask_erode'), plt.imshow(img_input_max_contour_mask_erode, cmap='gray')\n",
    "\n",
    "img_input_max_contour_mask_dilate = cv2.dilate(img_input_max_contour_mask_erode, None, iterations=MASK_DILATE_ITER)\n",
    "plt.subplot(165).set_title('img_input_max_contour_mask_dilate'), plt.imshow(img_input_max_contour_mask_dilate, cmap='gray')\n",
    "\n",
    "img_input_max_contour_mask_blur = cv2.GaussianBlur(img_input_max_contour_mask_dilate, (BLUR, BLUR), 0)\n",
    "plt.subplot(166).set_title('img_input_max_contour_mask_blur'), plt.imshow(img_input_max_contour_mask_blur, cmap='gray')\n",
    "\n",
    "\n",
    "# morph_kernel_7 = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "# img_input_max_contour_mask = cv2.dilate(img_input_max_contour_mask, morph_kernel_7, iterations=2)\n",
    "# plt.subplot(166).set_title('img_input_max_contour_mask'), plt.imshow(img_input_max_contour_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "img_test = img_input_max_contour_mask_blur.copy()\n",
    "img_test = np.asarray(img_test, dtype=np.uint8)\n",
    "# print(img_test[500][:])\n",
    "# img_rotated_canny = cv2.Canny(img_test, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "_, contours, _ = cv2.findContours(img_test, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in contours:\n",
    "    img_input_contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c),))\n",
    "    img_input_contour_sorted = sorted(img_input_contour_info, key=lambda c: c[2], reverse=True)\n",
    "    img_input_max_contour = img_input_contour_sorted[0]\n",
    "    \n",
    "cnt = cv2.convexHull(img_input_max_contour[0])\n",
    "rect = cv2.minAreaRect(cnt)\n",
    "# width = rect[1][0]\n",
    "# height = rect[1][1]\n",
    "\n",
    "\n",
    "# draw contour and min rectangle\n",
    "box = cv2.boxPoints(rect)\n",
    "box = np.int0(box)\n",
    "print(box)\n",
    "\n",
    "# show minimal area rectangle\n",
    "cv2.drawContours(img_input_canny, [img_input_max_contour[0]], 0, (0,0,255), 3)\n",
    "cv2.drawContours(img_input_canny, [box], 0, (0, 255, 0), 2)\n",
    "\n",
    "# get the percentage of contour area against the whole image\n",
    "max_contour_area = (img_input_max_contour[2])\n",
    "max_contour_rect_area =  rect[1][0] * rect[1][1]\n",
    "whole_area = img_input_canny_closing.shape[0] * img_input_canny_closing.shape[1]\n",
    "print('Contour area to whole percentage: ', max_contour_area, whole_area, max_contour_area/whole_area*100)\n",
    "print('Contour area to rect percentage: ', max_contour_area, max_contour_rect_area, max_contour_area/max_contour_rect_area*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_input_max_contour_mask_dilate - img_input_max_contour_mask_erode , cmap='gray')\n",
    "plt.imshow(img_input_max_contour_mask + img_input_max_contour_mask_dilate - img_input_max_contour_mask_erode , cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# View the mask performance by applying the mask on input color image\n",
    "# Background shall be lower pixel value now.\n",
    "# print(img_input_max_contour_mask[100][:])\n",
    "img_input_max_contour_mask = img_input_max_contour_mask_blur\n",
    "\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "\n",
    "img_input_max_contour_mask = np.asarray(img_input_max_contour_mask, dtype=np.uint8)\n",
    "ret, img_input_otsu_thresh =cv2.threshold(img_input_max_contour_mask, 0, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "\n",
    "plt.subplot(161).set_title('img_input_bgr_gray'), plt.imshow(img_input_bgr_gray, cmap='gray')\n",
    "plt.subplot(162).set_title('img_input_otsu_thresh'), plt.imshow(img_input_bgr_gray_otsu_thresh, cmap='gray')\n",
    "# img_denoised = np.multiply(img_input_otsu_thresh/255, img_input_bgr_gray)\n",
    "# plt.subplot(163).set_title('img_denoised'), plt.imshow(img_denoised, cmap='gray')\n",
    "\n",
    "img_input_otsu_thresh_dilate = cv2.dilate(img_input_otsu_thresh, MORPH_KERNEL_RECT_7, iterations=2)\n",
    "plt.subplot(163).set_title('img_input_otsu_thresh_dilate'), plt.imshow(img_input_otsu_thresh_dilate, cmap='gray')\n",
    "\n",
    "mask_stack = np.dstack([img_input_otsu_thresh_dilate]*3)    # Create 3-channel alpha mask\n",
    "\n",
    "#-- Blend masked img into MASK_COLOR background\n",
    "mask_stack = mask_stack.astype('float32') / 255.0\n",
    "print(mask_stack[100][:])\n",
    "img_input_uniform_float32 = img_input_uniform_color.astype('float32') / 255.0\n",
    "masked = (mask_stack * img_input_uniform_float32) + ((1-mask_stack) * MASK_COLOR)\n",
    "masked = (masked * 255).astype('uint8')\n",
    "# new_mask = ret\n",
    "img_input_uniform_masked = masked\n",
    "print(masked[100][:])\n",
    "plt.subplot(164).set_title('img_input_uniform_masked'), plt.imshow(img_input_uniform_masked, cmap='gray')\n",
    "\n",
    "hue, saturation, img_input_uniform_masked_hsv_gray = cv2.split(cv2.cvtColor(img_input_uniform_masked, cv2.COLOR_BGR2HSV))\n",
    "plt.subplot(165).set_title('img_input_uniform_masked_hsv_gray'), plt.imshow(img_input_uniform_masked_hsv_gray, cmap='gray')\n",
    "\n",
    "img_input_uniform_masked_brg_gray = cv2.cvtColor(img_input_uniform_masked, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(166).set_title('img_input_uniform_masked_brg_gray'), plt.imshow(img_input_uniform_masked_brg_gray, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# step 2: get the lines of the input image within the mask area\n",
    "image_input_for_lines_hsv_gray = img_input_uniform_masked_hsv_gray\n",
    "\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "plt.subplot(161).set_title('img_input_uniform_color'), plt.imshow(img_input_uniform_color)\n",
    "plt.subplot(162).set_title('image_input_for_lines_hsv_gray'), plt.imshow(image_input_for_lines_hsv_gray, cmap='gray')\n",
    "\n",
    "# non-plain kernal gives better lines\n",
    "img_input_for_lines_hough = cv2.filter2D(image_input_for_lines_hsv_gray, -1, kernel=np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32))\n",
    "plt.subplot(163).set_title('img_input_for_lines_hough'), plt.imshow(img_input_for_lines_hough, cmap='gray')\n",
    "\n",
    "img_lines_hough_opening = cv2.morphologyEx(img_input_for_lines_hough, cv2.MORPH_OPEN, MORPH_KERNEL_RECT_5)\n",
    "plt.subplot(164).set_title('img_lines_hough_opening'), plt.imshow(img_lines_hough_opening, cmap='gray')\n",
    "\n",
    "img_lines_hough_opening_ad_thresh = cv2.adaptiveThreshold(img_lines_hough_opening, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 9)\n",
    "plt.subplot(165).set_title('img_lines_hough_opening_ad_thresh'), plt.imshow(img_lines_hough_opening_ad_thresh, cmap='gray')\n",
    "\n",
    "minLineLength = 500\n",
    "maxLineGap = 20\n",
    "img_hough_lines = img_input_uniform_color.copy()\n",
    "lines = cv2.HoughLinesP(img_lines_hough_opening_ad_thresh, 1, np.pi/180, 100, minLineLength, maxLineGap)\n",
    "print('Total lines: ', len(lines))\n",
    "lines_sort = sorted(lines, key=lambda a: math.hypot(a[0][2]-a[0][0], a[0][3]-a[0][1]), reverse=True)\n",
    "\n",
    "for line in lines_sort[0:len(lines_sort)]:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "#         print(x1,y1,x2,y2)\n",
    "        cv2.line(img_hough_lines,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "        \n",
    "plt.subplot(166).set_title('img_hough_lines'), plt.imshow(img_hough_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# step 3: get the angle and do the rotation\n",
    "toangle = lambda a :shape_operation.getAngleOfTwoPoints(a[0][0], a[0][1], a[0][2], a[0][3])\n",
    "line_angles = np.array([toangle(xi) for xi in lines])\n",
    "\n",
    "print(len(line_angles))\n",
    "# print(line_angles)\n",
    "\n",
    "n, bins, patches = plt.hist(x=line_angles, bins=180, range=[-89,90], color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('My Very Own Histogram')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
    "\n",
    "fig = plt.figure(figsize=(28, 20)) \n",
    "angle = np.argmax(n)-89\n",
    "print('Angle: ', angle)\n",
    "(h, w) = img_input_uniform_color.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "img_rotated_color = cv2.warpAffine(img_input_uniform_color, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "plt.subplot(171).set_title('img_rotated_color'), plt.imshow(img_rotated_color, cmap='gray')\n",
    "\n",
    "\n",
    "# draw rotated image\n",
    "hue, saturation, img_rotated_hsv_gray = cv2.split(cv2.cvtColor(img_rotated_color, cv2.COLOR_BGR2HSV))\n",
    "plt.subplot(172).set_title('img_rotated_hsv_gray'), plt.imshow(img_rotated_hsv_gray, cmap='gray')\n",
    "\n",
    "img_rotated_hsv_gray_blur = cv2.GaussianBlur(img_rotated_hsv_gray, (3, 3), 0)\n",
    "plt.subplot(173).set_title('img_rotated_hsv_gray_blur'), plt.imshow(img_rotated_hsv_gray_blur, cmap='gray')\n",
    "\n",
    "ret, img_rotated_hsv_gray_otsu_thresh =cv2.threshold(img_rotated_hsv_gray_blur, 0, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "plt.subplot(174).set_title('img_rotated_hsv_gray_otsu_thresh'), plt.imshow(img_rotated_hsv_gray_otsu_thresh, cmap='gray')\n",
    "\n",
    "# plt.subplot(166).set_title('img_rotated_max_contour_mask_blur'), plt.imshow(img_rotated_max_contour_mask, cmap='gray')\n",
    "img_rotated_bgr_gray = cv2.cvtColor(img_rotated_color, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(175).set_title('img_rotated_bgr_gray'), plt.imshow(img_rotated_bgr_gray, cmap='gray')\n",
    "\n",
    "img_rotated_bgr_gray_blur = cv2.GaussianBlur(img_rotated_bgr_gray, (3, 3), 0)\n",
    "plt.subplot(176).set_title('img_rotated_bgr_gray_blur'), plt.imshow(img_rotated_bgr_gray_blur, cmap='gray')\n",
    "\n",
    "ret, img_rotated_bgr_gray_otsu_thresh =cv2.threshold(img_rotated_bgr_gray, 0, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "plt.subplot(177).set_title('img_rotated_bgr_gray_otsu_thresh'), plt.imshow(img_rotated_bgr_gray_otsu_thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# step 4: we have the rotated image. Now, repeat to get the contour and the lines of the rotated image\n",
    "# - step 1: get the contour mask of the rotated image.\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "\n",
    "# img_rotated_canny = cv2.Canny(img_rotated_otsu_thresh, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "img_rotated_canny = cv2.Canny(img_rotated_bgr_gray, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "# plt.subplot(161).set_title('img_rotated_canny'), plt.imshow(img_rotated_canny, cmap='gray')\n",
    "\n",
    "img_rotated_canny_closing = cv2.morphologyEx(img_rotated_canny, cv2.MORPH_CLOSE, MORPH_KERNEL_RECT_7)\n",
    "# img_rotated_closing = 255 - img_rotated_closing\n",
    "# plt.subplot(162).set_title('img_rotated_canny_closing'), plt.imshow(img_rotated_canny_closing, cmap='gray')\n",
    "\n",
    "img_rotated_contour_info = []\n",
    "# _, contours, _ = cv2.findContours(img_rotated_closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# _, contours, _ = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "_, contours, _ = cv2.findContours(img_rotated_canny_closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in contours:\n",
    "    img_rotated_contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c),))\n",
    "    img_rotated_contour_sorted = sorted(img_rotated_contour_info, key=lambda c: c[2], reverse=True)\n",
    "    img_rotated_max_contour = img_rotated_contour_sorted[0]\n",
    "\n",
    "# get the percentage of contour area against the whole image\n",
    "max_contour_area = (img_rotated_max_contour[2])\n",
    "whole_area = img_rotated_canny_closing.shape[0] * img_rotated_canny_closing.shape[1]\n",
    "print('Contour area percentage: ', max_contour_area, whole_area, max_contour_area/whole_area*100)\n",
    "\n",
    "mix_background = max_contour_area < whole_area * 0.9\n",
    "if (mix_background):  # pixel value of background is higher than the object\n",
    "    plt.subplot(161).set_title('img_rotated_canny'), plt.imshow(img_rotated_canny, cmap='gray')\n",
    "    plt.subplot(162).set_title('img_rotated_canny_closing'), plt.imshow(img_rotated_canny_closing, cmap='gray')\n",
    "\n",
    "else:  # contour is almost the whole image, probablely the background has high pixel value\n",
    "    img_rotated_canny = cv2.Canny(img_rotated_bgr_gray_otsu_thresh, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "    plt.subplot(161).set_title('img_rotated_canny'), plt.imshow(img_rotated_canny_closing, cmap='gray')\n",
    "\n",
    "    img_rotated_canny_closing = cv2.morphologyEx(img_rotated_canny, cv2.MORPH_CLOSE, MORPH_KERNEL_RECT_7)\n",
    "        # img_rotated_closing = 255 - img_rotated_closing\n",
    "    plt.subplot(162).set_title('img_rotated_closing'), plt.imshow(img_rotated_canny_closing, cmap='gray')\n",
    "\n",
    "    img_rotated_contour_info = []\n",
    "        # _, contours, _ = cv2.findContours(img_rotated_closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # _, contours, _ = cv2.findContours(closing, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    _, contours, _ = cv2.findContours(img_rotated_canny_closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        img_rotated_contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c),))\n",
    "    img_rotated_contour_sorted = sorted(img_rotated_contour_info, key=lambda c: c[2], reverse=True)\n",
    "    img_rotated_max_contour = img_rotated_contour_sorted[0]\n",
    "\n",
    "img_rotated_max_contour_mask = np.zeros(img_rotated_canny_closing.shape)\n",
    "cv2.fillConvexPoly(img_rotated_max_contour_mask, img_rotated_max_contour[0], (255, 0, 0))\n",
    "plt.subplot(163).set_title('img_rotated_max_contour_mask'), plt.imshow(img_rotated_max_contour_mask, cmap='gray')\n",
    "\n",
    "img_rotated_max_contour_mask_erode = cv2.erode(img_rotated_max_contour_mask, None, iterations=MASK_ERODE_ITER)\n",
    "plt.subplot(164).set_title('img_rotated_max_contour_mask_erode'), plt.imshow(img_rotated_max_contour_mask_erode, cmap='gray')\n",
    "\n",
    "img_rotated_max_contour_mask_dilate = cv2.dilate(img_rotated_max_contour_mask_erode, None, iterations=MASK_DILATE_ITER)\n",
    "plt.subplot(165).set_title('img_rotated_max_contour_mask_dilate'), plt.imshow(img_rotated_max_contour_mask_dilate, cmap='gray')\n",
    "\n",
    "img_rotated_max_contour_mask_blur = cv2.GaussianBlur(img_rotated_max_contour_mask_dilate, (BLUR, BLUR), 0)\n",
    "plt.subplot(166).set_title('img_rotated_max_contour_mask_blur'), plt.imshow(img_rotated_max_contour_mask_blur, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# step 4: we have the rotated image. Now, repeat to get the contour and the lines of the rotated image\n",
    "# step - 2: get the the mask area of the rotated image\n",
    "\n",
    "img_rotated_max_contour_mask = img_rotated_max_contour_mask_blur\n",
    "\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "\n",
    "img_rotated_max_contour_mask = np.asarray(img_rotated_max_contour_mask, dtype=np.uint8)\n",
    "ret, img_rotated_otsu_thresh =cv2.threshold(img_rotated_max_contour_mask, 0, 255, cv2.THRESH_BINARY|cv2.THRESH_OTSU)\n",
    "\n",
    "plt.subplot(161).set_title('img_rotated_bgr_gray'), plt.imshow(img_rotated_bgr_gray, cmap='gray')\n",
    "plt.subplot(162).set_title('img_rotated_otsu_thresh'), plt.imshow(img_rotated_bgr_gray_otsu_thresh, cmap='gray')\n",
    "# img_denoised = np.multiply(img_rotated_otsu_thresh/255, img_rotated_bgr_gray)\n",
    "# plt.subplot(163).set_title('img_denoised'), plt.imshow(img_denoised, cmap='gray')\n",
    "\n",
    "img_rotated_otsu_thresh_dilate = cv2.dilate(img_rotated_otsu_thresh, MORPH_KERNEL_RECT_7, iterations=1)\n",
    "plt.subplot(163).set_title('img_rotated_otsu_thresh_dilate'), plt.imshow(img_rotated_otsu_thresh_dilate, cmap='gray')\n",
    "\n",
    "mask_stack = np.dstack([img_rotated_otsu_thresh_dilate]*3)    # Create 3-channel alpha mask\n",
    "\n",
    "#-- Blend masked img into MASK_COLOR background\n",
    "mask_stack = mask_stack.astype('float32') / 255.0\n",
    "print(mask_stack[100][:])\n",
    "img_rotated_uniform_float32 = img_rotated_color.astype('float32') / 255.0\n",
    "masked = (mask_stack * img_rotated_uniform_float32) + ((1-mask_stack) * MASK_COLOR)\n",
    "masked = (masked * 255).astype('uint8')\n",
    "# new_mask = ret\n",
    "img_rotated_uniform_masked = masked\n",
    "print(masked[100][:])\n",
    "plt.subplot(164).set_title('img_rotated_uniform_masked'), plt.imshow(img_rotated_uniform_masked, cmap='gray')\n",
    "\n",
    "hue, saturation, img_rotated_uniform_masked_hsv_gray = cv2.split(cv2.cvtColor(img_rotated_uniform_masked, cv2.COLOR_BGR2HSV))\n",
    "plt.subplot(165).set_title('img_rotated_uniform_masked_hsv_gray'), plt.imshow(img_rotated_uniform_masked_hsv_gray, cmap='gray')\n",
    "\n",
    "img_rotated_uniform_masked_brg_gray = cv2.cvtColor(img_rotated_uniform_masked, cv2.COLOR_BGR2GRAY)\n",
    "plt.subplot(166).set_title('img_rotated_uniform_masked_brg_gray'), plt.imshow(img_rotated_uniform_masked_brg_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-990c0e4a5872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# step 4: we have the rotated image. Now, repeat to get the contour and the lines of the rotated image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# step - 3: get the lines of the rotated image within the mask area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage_rotated_contoured_hsv_gray_for_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_rotated_uniform_masked_hsv_gray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_rotated_uniform_masked_hsv_gray' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'img_rotated_uniform_masked_hsv_gray' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# step 4: we have the rotated image. Now, repeat to get the contour and the lines of the rotated image\n",
    "# step - 3: get the lines of the rotated image within the mask area\n",
    "image_rotated_contoured_hsv_gray_for_lines = img_rotated_uniform_masked_hsv_gray\n",
    "\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "plt.subplot(161).set_title('img_rotated_color'), plt.imshow(img_rotated_color)\n",
    "plt.subplot(162).set_title('image_rotated_contoured_hsv_gray_for_lines'), plt.imshow(image_rotated_contoured_hsv_gray_for_lines, cmap='gray')\n",
    "\n",
    "# non-plain kernal gives better lines\n",
    "img_rotated_contoured_for_lines_hough = cv2.filter2D(image_rotated_contoured_hsv_gray_for_lines, -1, kernel=np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32))\n",
    "plt.subplot(163).set_title('img_rotated_contoured_for_lines_hough'), plt.imshow(img_rotated_contoured_for_lines_hough, cmap='gray')\n",
    "\n",
    "img_rotated_contoured_lines_hough_opening = cv2.morphologyEx(img_rotated_contoured_for_lines_hough, cv2.MORPH_OPEN, MORPH_KERNEL_RECT_5)\n",
    "plt.subplot(164).set_title('img_rotated_contoured_lines_hough_opening'), plt.imshow(img_rotated_contoured_lines_hough_opening, cmap='gray')\n",
    "\n",
    "img_rotated_contoured_lines_hough_opening_ad_thresh = cv2.adaptiveThreshold(img_rotated_contoured_lines_hough_opening, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 9)\n",
    "plt.subplot(165).set_title('img_rotated_contoured_lines_hough_opening_ad_thresh'), plt.imshow(img_rotated_contoured_lines_hough_opening_ad_thresh, cmap='gray')\n",
    "\n",
    "minLineLength = 500\n",
    "maxLineGap = 20\n",
    "img_rotated_contoured_hough_lines = image_rotated_contoured_hsv_gray_for_lines.copy()\n",
    "lines_rotated_contoured_image_contour_area = cv2.HoughLinesP(img_rotated_contoured_lines_hough_opening_ad_thresh, 1, np.pi/180, 100, minLineLength, maxLineGap)\n",
    "print('Total lines: ', len(lines_rotated_contoured_image_contour_area))\n",
    "lines_sorted_rotated_contoured_image_contour_area = sorted(lines_rotated_contoured_image_contour_area, key=lambda a: math.hypot(a[0][2]-a[0][0], a[0][3]-a[0][1]), reverse=True)\n",
    "\n",
    "for line_rotated_contoured_image_contour_area in lines_sorted_rotated_contoured_image_contour_area[0:len(lines_sorted_rotated_contoured_image_contour_area)]:\n",
    "    for x1,y1,x2,y2 in line_rotated_contoured_image_contour_area:\n",
    "    #         print(x1,y1,x2,y2)\n",
    "        cv2.line(img_rotated_contoured_hough_lines,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "plt.subplot(166).set_title('img_rotated_contoured_hough_lines'), plt.imshow(img_rotated_contoured_hough_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# step 5: form rectangle by lines which are in the contour area.\n",
    "fig = plt.figure(figsize=(28, 20))\n",
    "\n",
    "import importlib\n",
    "importlib.reload(shape_operation)\n",
    "\n",
    "x1, y1, x2, y2 = shape_operation.getFourExtremePointsFromLinesByAngle(lines_rotated_contoured_image_contour_area, 0, 90)\n",
    "print(x1, y1, x2, y2)\n",
    "cv2.rectangle(img_rotated_contoured_hough_lines, (x1,y1), (x2,y2), (0, 255, 0), 2);\n",
    "plt.subplot(161).set_title('img_rotated_contoured_hough_lines_rectangle'), plt.imshow(img_rotated_contoured_hough_lines)\n",
    "\n",
    "img_foreground_output = img_rotated_color[y1:y2, x1:x2]\n",
    "plt.subplot(162).set_title('img_foreground_output'), plt.imshow(img_foreground_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# # step 5: remove lines that is not in the contour area.\n",
    "# fig = plt.figure(figsize=(28, 20))\n",
    "# # print(img_rotated_max_contour_mask[0][:])\n",
    "\n",
    "# img_rotated_max_contour_mask = np.asarray(img_rotated_max_contour_mask, dtype=np.uint8)\n",
    "# # print(img_rotated_max_contour_mask[0][:])\n",
    "# # img_rotated_max_contour_mask_gray = cv2.cvtColor(img_rotated_max_contour_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # hsv = cv2.cvtColor(img_rotated_max_contour_mask, cv2.COLOR_BGR2HSV)\n",
    "# # hue, saturation, img_rotated_max_contour_mask_hsv_gray = cv2.split(hsv)\n",
    "# # plt.subplot(162).set_title('img_rotated_max_contour_mask_hsv_gray'), plt.imshow(img_rotated_max_contour_mask_hsv_gray, cmap='gray')\n",
    "\n",
    "# # img_rotated_contour_mask_ad_thresh = cv2.adaptiveThreshold(img_rotated_max_contour_mask, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 9)\n",
    "# # plt.subplot(161).set_title('img_rotated_contour_mask_ad_thresh'), plt.imshow(img_rotated_contour_mask_ad_thresh, cmap='gray')\n",
    "# # print('')\n",
    "# # print(img_rotated_contour_mask_ad_thresh[0][:])\n",
    "\n",
    "# ret2, img_rotated_contour_mask_OSTU_thresh = cv2.threshold(img_rotated_max_contour_mask, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# plt.subplot(161).set_title('img_rotated_contour_mask_OSTU_thresh'), plt.imshow(img_rotated_contour_mask_OSTU_thresh, cmap='gray')\n",
    "# # print(img_rotated_contour_mask_OSTU_thresh[0][:])  0 and 255\n",
    "\n",
    "# mask = img_rotated_contour_mask_OSTU_thresh\n",
    "\n",
    "# new_lines = []\n",
    "# for line in lines_sort[0:len(lines_sort)]:\n",
    "#     for x1,y1,x2,y2 in line:\n",
    "# #         print(x1,y1,x2,y2)\n",
    "#         if (mask[y1][x1] > 0 and mask[y2][x2] > 0):\n",
    "#             new_lines.append(line)\n",
    "\n",
    "# print('new lines: ', len(new_lines))\n",
    "\n",
    "\n",
    "# x1, y1, x2, y2 = shape_operation.getFourExtremePointsFromLines(new_lines)\n",
    "# print(x1, y1, x2, y2)\n",
    "# cv2.rectangle(img_rotated_lines, (x1,y1), (x2,y2), (0, 255, 0), 2);\n",
    "# plt.subplot(162).set_title('rectangle'), plt.imshow(img_rotated_lines)\n",
    "\n",
    "# img_foreground_output = img_rotated[y1:y2, x1:x2]\n",
    "# plt.subplot(163).set_title('img_foreground_output'), plt.imshow(img_foreground_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}